{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sparse_reg(Theta, char_sizes=None, row_norms=None, valid_single=None, opts=None, avoid=[]):\n",
    "# compute sparse regression on Theta * Xi = 0\n",
    "# Theta: matrix of integrated terms\n",
    "# char_sizes: vector of characteristic term sizes (per column)\n",
    "# row_norms: desired norm of each row\n",
    "# valid_single: vector of 1s/0s (valid single term model/not)\n",
    "# opts: dictionary of options\n",
    "# avoid: coefficient vectors to be orthogonal to\n",
    "\n",
    "    opt_defaults = {'threshold': \"'pareto'\", 'brute_force': True, 'delta': 1e-10, 'epsilon': 1e-2, 'gamma': 2, 'verbose': False, 'n_terms': -1}\n",
    "\n",
    "    # read options\n",
    "    if opts is None:\n",
    "        opts = dict() # to simplify conditional logic\n",
    "    for opt in opt_defaults.keys():\n",
    "        opt_value = opts[opt] if (opt in opts) else opt_defaults[opt]\n",
    "        exec(f'{opt}={opt_value}', globals())\n",
    "    \n",
    "    Theta = np.copy(Theta) # avoid bugs where array is modified in place\n",
    "        \n",
    "    if row_norms is not None:\n",
    "        for row in range(len(row_norms)):\n",
    "            rownm = np.linalg.norm(Theta[row, :])\n",
    "            if rownm != 0:\n",
    "                Theta[row, :] *= (row_norms[row]/rownm)\n",
    "            \n",
    "    Thetanm = np.linalg.norm(Theta)\n",
    "    M = 100*Theta.shape[0]\n",
    "    for Xi in avoid:\n",
    "        Theta = np.vstack([Theta, M*np.transpose(Xi)]) # acts as a constraint - weights should be orthogonal to Xi\n",
    "    \n",
    "    h, w = Theta.shape\n",
    "    beta = w/h # aspect ratio\n",
    "    \n",
    "    if valid_single is None:\n",
    "        valid_single = np.ones(shape=(w, 1))\n",
    "        \n",
    "    if char_sizes is not None:\n",
    "        char_sizes = np.array(char_sizes)\n",
    "        char_sizes /= np.max(char_sizes)\n",
    "        for term in range(len(char_sizes)):\n",
    "            #char_sizes[term] = np.linalg.norm(Theta[:, term]) # check what happens if all columns treated \"equally\"\n",
    "            Theta[:, term] = Theta[:, term] / char_sizes[term] # renormalize by characteristic size\n",
    "    #print('char_sizes:', char_sizes)\n",
    "    #print(Theta[0, :])\n",
    "\n",
    "    U, Sigma, V = np.linalg.svd(Theta, full_matrices=True)\n",
    "    V = V.transpose() # since numpy SVD returns the transpose\n",
    "    Xi = V[:, -1]\n",
    "    if verbose:\n",
    "        #print(\"Sigma:\", Sigma)\n",
    "        #Sigmas = Sigma[Sigma[:]>0]\n",
    "        Sigma_shrink = [opt_shrinker(s, beta) for s in Sigma]\n",
    "        #print(\"Sigma_shrink:\", Sigma_shrink)\n",
    "        print(\"V:\", V)\n",
    "        print(\"scores:\", np.log(Sigma)) # np.log(Sigmas)/np.min(Sigmas)\n",
    "    lambd = np.linalg.norm(Theta@Xi)\n",
    "    if verbose:\n",
    "        print('lambda:', lambd)\n",
    "    # find best one-term model as well\n",
    "    nrm = np.zeros(w)\n",
    "    for term in range(w):\n",
    "        nrm[term] = np.linalg.norm(Theta[:, term]) / valid_single[term]\n",
    "        lambda1, ind_single = min(nrm), np.argmin(nrm)\n",
    "        if verbose:\n",
    "            print(f'nrm[{term}]:', nrm[term])\n",
    "    smallinds = np.zeros(w)\n",
    "    margins = np.zeros(w) # increases in residual per time step\n",
    "    lambdas = np.zeros(w)\n",
    "    lambdas[0] = lambd\n",
    "    Xis = np.zeros(shape=(w, w)) # record coefficients\n",
    "    for i in range(w-1):\n",
    "        Xis[i] = Xi\n",
    "        if brute_force:\n",
    "           # product of the coefficient and characteristic size of library function\n",
    "           res_inc = np.ones(shape=(w,1))*np.inf\n",
    "        product = np.zeros(shape=(w,1))\n",
    "        for p_ind in range(w):\n",
    "            if brute_force:\n",
    "                if smallinds[p_ind]==0:\n",
    "                    # Try dropping each term\n",
    "                    smallinds_copy = np.copy(smallinds)\n",
    "                    smallinds_copy[p_ind] = 1\n",
    "                    Xi_copy = np.copy(Xi)\n",
    "                    Xi_copy[p_ind] = 0\n",
    "                    _, _, V = np.linalg.svd(Theta[:, smallinds_copy==0], full_matrices=True)\n",
    "                    V = V.transpose()\n",
    "                    Xi_copy[smallinds_copy==0] = V[:, -1]\n",
    "                    res_inc[p_ind] = np.linalg.norm(Theta@Xi_copy)/lambd\n",
    "            else:\n",
    "                col = Theta[:, p_ind]\n",
    "                # project out other columns\n",
    "                for q_ind in range(w):\n",
    "                    if (p_ind != q_ind) and smallinds[q_ind]==0:\n",
    "                        other_col = Theta[:, q_ind]\n",
    "                        col = col - np.dot(col, other_col)/np.linalg.norm(other_col)**2*other_col\n",
    "                #product[p_ind] = np.linalg.norm(Xi[p_ind]*col)/np.linalg.norm(Theta)\n",
    "                product[p_ind] = np.linalg.norm(Xi[p_ind]*col)\n",
    "        if brute_force:\n",
    "            Y, I = min(res_inc), np.argmin(res_inc)\n",
    "            if verbose:\n",
    "                print(\"Y:\", Y, \"I:\", I)\n",
    "            margins[i] = Y\n",
    "            if verbose:\n",
    "                #print('res_inc:', res_inc)\n",
    "                if threshold != \"multiplicative\":\n",
    "                    print(\"i\", i, \"lambda\", lambd) # for pareto plot\n",
    "            if (Y<=gamma) or (threshold != \"threshold\") or (lambd<=delta):\n",
    "                smallinds[I] = 1\n",
    "                Xi[I] = 0\n",
    "                _, _, V = np.linalg.svd(Theta[:, smallinds==0], full_matrices=True)\n",
    "                V = V.transpose()\n",
    "                Xi[smallinds==0] = V[:, -1]\n",
    "                lambd = np.linalg.norm(Theta@Xi)\n",
    "                lambdas[i+1] = lambd\n",
    "                if sum(smallinds==0)==1:\n",
    "                        break\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(\"Y:\", Y, \"I:\", I)\n",
    "                break\n",
    "        else:\n",
    "            product[smallinds==1]=np.inf\n",
    "            Y, I = min(product), np.argmin(product)\n",
    "            if verbose:\n",
    "                print(\"Y:\", Y, \"I:\", I)\n",
    "            smallinds[I] = 1\n",
    "            if sum(smallinds==0)==1:\n",
    "                break\n",
    "            #if verbose:\n",
    "                #print(\"prod:\", product.transpose())\n",
    "            Xi_old = Xi\n",
    "            Xi[smallinds==1] = 0 # set negligible terms to 0\n",
    "            _ , _, V = np.linalg.svd(Theta[:,smallinds==0], full_matrices=True)\n",
    "            V = V.transpose()\n",
    "            Xi[smallinds==0] = V[:, -1]\n",
    "            lambda_old = lambd\n",
    "            lambd = np.linalg.norm(Theta@Xi)\n",
    "            lambdas[i+1] = lambd\n",
    "            margin = lambd/lambda_old\n",
    "            if verbose:\n",
    "                print(\"lambda:\", lambd, \" margin:\", margin) \n",
    "            margins[i] = margin\n",
    "            if (margin > gamma) and (lambd>delta) and (threshold==\"threshold\"):\n",
    "                print(\"I:\", I)\n",
    "                Xi = Xi_old\n",
    "                print(\"Xi:\", Xi)\n",
    "                break\n",
    "    Xis[i+1] = Xi\n",
    "    if threshold==\"pareto\":\n",
    "        Y_mar, I_mar = max(margins), np.argmax(margins)\n",
    "        if n_terms>1:\n",
    "            I_mar = sum(margins>0)-n_terms\n",
    "        if verbose:\n",
    "            print(\"margins:\", margins)\n",
    "            print(\"Y_mar:\", Y_mar, \"I_mar:\", I_mar)\n",
    "        I_mar = max(np.argmax(lambdas>delta)-1, I_mar)\n",
    "        stopping_point = I_mar-1\n",
    "        Xi = Xis[I_mar]; #stopping_point\n",
    "        lambd = np.linalg.norm(Theta@Xi);\n",
    "    elif threshold==\"multiplicative\":\n",
    "        I_sm = np.argmax((lambdas>epsilon*lambda1) & (lambdas>delta))-1\n",
    "        Xi = Xis[I_sm] #stopping_point\n",
    "        lambd = np.linalg.norm(Theta@Xi)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Xis:\", Xis)\n",
    "    # now compare single term and sparsified model\n",
    "    if verbose:\n",
    "        print(\"lambda:\", lambd, \"lambda1:\", lambda1)\n",
    "        print(\"lambdas:\", lambdas)\n",
    "    best_term = ind_single\n",
    "    #print(\"Xi1:\", Xi)\n",
    "    if char_sizes is not None:\n",
    "        Xi = Xi / char_sizes # renormalize by char. size\n",
    "        #print(\"Xi2:\", Xi)\n",
    "        #nm = np.linalg.norm(Xi)\n",
    "        ## divide errors by the norm to make errors consistent\n",
    "        #lambd /= nm\n",
    "        #lambda1 /= nm\n",
    "    #divide errors by square root of number of rows to make errors consistent\n",
    "    #lambd /= h**0.5\n",
    "    #lambda1 /= h**0.5\n",
    "    if -min(Xi)>max(Xi): # ensure vectors are \"positive\"\n",
    "        Xi = -Xi\n",
    "    Xi = Xi/max(Xi) # make largest coeff 1\n",
    "    # make residuals relative to original norm(Theta)*norm(Xi)\n",
    "    nm = np.linalg.norm(Xi)\n",
    "    lambd /= (nm*Thetanm)\n",
    "    lambda1 /= Thetanm\n",
    "    \n",
    "    return Xi, lambd, best_term, lambda1\n",
    "\n",
    "def opt_shrinker(y, beta):\n",
    "    if y <= 1+np.sqrt(beta):\n",
    "        return 0\n",
    "    else:\n",
    "        return np.sqrt((y*y-beta-1)**2-4*beta)/y\n",
    "    \n",
    "def regress(Theta, col_numbers): # regression on a fixed set of terms\n",
    "    h, w = Theta.shape\n",
    "    Thetanm = np.linalg.norm(Theta)\n",
    "    smallinds = np.ones(shape=(w,))\n",
    "    Xi = np.zeros(shape=(w,))\n",
    "    smallinds[np.array(col_numbers)] = 0\n",
    "    _, _, V = np.linalg.svd(Theta[:, smallinds==0], full_matrices=True)\n",
    "    V = V.transpose()\n",
    "    Xi[smallinds==0] = V[:, -1]\n",
    "    lambd = np.linalg.norm(Theta@Xi)\n",
    "    if -min(Xi)>max(Xi): # ensure vectors are \"positive\"\n",
    "        Xi = -Xi\n",
    "    Xi = Xi/max(Xi) # make largest coeff 1\n",
    "    # make residuals relative to original norm(Theta)*norm(Xi)\n",
    "    nm = np.linalg.norm(Xi)\n",
    "    lambd /= (nm*Thetanm)\n",
    "    return Xi, lambd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
