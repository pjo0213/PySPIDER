{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@author: Daniel\n",
    "\n",
    "Note: make sure latest version of scipy is installed\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import sparse\n",
    "from scipy.spatial import KDTree\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "from utils import save, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 640\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n"
     ]
    }
   ],
   "source": [
    " L = 80.0 # size of domain\n",
    "rho = 0.1 # density of particles\n",
    "N = int(rho*L**2) # number of particles\n",
    "print(\"N =\",N)\n",
    " \n",
    "deltat = 1.0 # time step\n",
    "vmax = 4/15 # max particle speed\n",
    "vmax_comp = vmax/2**0.5 # max particle speed in a given component\n",
    "iterations = 250 # number of time steps\n",
    "\n",
    "def get_v(p): # function describing v as a functioning of initial position\n",
    "    return (p-L/2)/(L/2)*vmax\n",
    "\n",
    "all_pos = np.zeros(shape=(N,2,iterations))\n",
    "all_v = np.zeros(shape=(N,2, iterations))\n",
    "pos = np.random.uniform(L/3,2*L/3,size=(N,2)) # positions of particles\n",
    "#v = np.random.uniform(-vmax_comp, vmax_comp, size=(N,2)) # orientations of particles\n",
    "v = np.zeros(shape=(N,2))\n",
    "for i in range(N):\n",
    "    v[i, :] = get_v(pos[i, :])\n",
    "\n",
    "fig, ax= plt.subplots(figsize=(6,6))\n",
    " \n",
    "qv = ax.quiver(pos[:,0], pos[:,1], v[:,0], v[:, 1], np.arctan2(v[:,0], v[:,1]), clim=[-np.pi, np.pi])\n",
    "ax.axis([0, L, 0, L])\n",
    " \n",
    "def animate(i):\n",
    "    if i%10==0:\n",
    "        print(i)\n",
    "    global pos\n",
    "    \n",
    "    pos += deltat*v\n",
    "    # periodic boundary conditions\n",
    "    pos[pos>L] -= L\n",
    "    pos[pos<0] += L\n",
    "    \n",
    "    all_pos[:, :, i-1] = pos\n",
    "    all_v[:, :, i-1] = v\n",
    " \n",
    "    qv.set_offsets(pos)\n",
    "    qv.set_UVC(v[:,0], v[:, 1], np.arctan2(v[:,0], v[:,1]))\n",
    "    return qv,\n",
    " \n",
    "anim = FuncAnimation(fig, animate, np.arange(1, iterations+1), interval=1, blit=True)\n",
    "anim.save('burgers.mp4', fps=30, extra_args=['-vcodec', 'libx264'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save(filename, *args):\n",
    "#     with open(filename, 'wb') as f:\n",
    "#         for arr in args:\n",
    "#             np.save(f, arr)\n",
    "            \n",
    "# def load(filename, nload):\n",
    "#     to_load = []\n",
    "#     with open(filename, 'rb') as f:\n",
    "#         for i in range(nload):\n",
    "#             to_load.append(np.load(f))\n",
    "#     return tuple(to_load)\n",
    "    \n",
    "save('data_bu.npy', all_pos, all_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coarse-graining\n",
    "res = 4 # number of points per unit length of L\n",
    "width = int(res*L) # length of domain in grid points\n",
    "\n",
    "# binned density \n",
    "binned_pts = np.zeros(shape=(width, width, iterations))\n",
    "# binned rho*velocity\n",
    "binned_rv = np.zeros(shape=(width, width, iterations, 2))\n",
    "# binned velocity (not actually used, for illustration only)\n",
    "binned_v = np.zeros(shape=(width, width, iterations, 2))\n",
    "\n",
    "for i in range(iterations):\n",
    "    for j in range(N):\n",
    "        pt = all_pos[j, :, i]*res\n",
    "        binned_pts[int(pt[0]), int(pt[1]), i] += 1\n",
    "        binned_rv[int(pt[0]), int(pt[1]), i, :] += all_v[j, :, i]\n",
    "binned_pts *= res**2\n",
    "binned_rv *= res**2\n",
    "for x in range(width):\n",
    "    for y in range(width):\n",
    "        for z in range(iterations):\n",
    "            if binned_pts[x, y, z]>0:\n",
    "                binned_v[x, y, z, :] = binned_rv[x, y, z, :]/binned_pts[x, y, z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3)= plt.subplots(ncols=3, figsize=(18,6))\n",
    "ax1.imshow(binned_pts[:, :, 100], extent=[0, L, 0, L])\n",
    "ax2.imshow(binned_v[:, :, 100, 0], extent=[0, L, 0, L])\n",
    "ax3.imshow(binned_v[:, :, 100, 1], extent=[0, L, 0, L])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "sigma0 = 2\n",
    "\n",
    "# def coarse_grain(binned, positions=None):\n",
    "#     # positions - optional argument for tuning width of kernel and such\n",
    "#     sigma = sigma0*res # width of convolution kernel\n",
    "#     sigma_vector = np.zeros(shape=(len(binned.shape),1))\n",
    "#     sigma_vector[0:2] = sigma\n",
    "#     smoothed = gaussian_filter(binned, sigma_vector, mode='wrap', truncate=12)\n",
    "#     return smoothed\n",
    "\n",
    "rho = coarse_grain(binned_pts, sigma0*res)\n",
    "rv = coarse_grain(binned_rv, sigma0*res)\n",
    "v = np.copy(rv)\n",
    "\n",
    "nzind = rho[:]>0\n",
    "zind = rho[:]==0\n",
    "v[nzind, 0] = rv[nzind, 0]/rho[nzind]\n",
    "v[zind, 0] = 0\n",
    "v[nzind, 1] = rv[nzind, 1]/rho[nzind]\n",
    "v[zind, 1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3)= plt.subplots(ncols=3, figsize=(18,6))\n",
    "ax1.imshow(rho[:, :, 100], extent=[0, L, 0, L])\n",
    "ax2.imshow(rv[:, :, 100, 1], extent=[0, L, 0, L])\n",
    "ax3.imshow(v[:, :, 100, 1], extent=[0, L, 0, L])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coarse-graining\n",
    "res = 4 # number of points per unit length of L\n",
    "width = int(res*L) # length of domain in grid points\n",
    "\n",
    "rho_tuned = np.zeros(shape=(width, width, iterations))\n",
    "rv_tuned = np.zeros(shape=(width, width, iterations, 2))\n",
    "v_tuned = np.zeros(shape=(width, width, iterations, 2))\n",
    "rhom = np.mean(rho)\n",
    "\n",
    "# def gauss1d(x0, sigma, truncate=12, xmin=0, xmax=0, wrap=True):\n",
    "#     offset = int(x0)\n",
    "#     halfwidth = int(np.ceil(truncate*sigma))\n",
    "#     if not wrap:\n",
    "#         mn = np.max([offset-halfwidth, xmin])\n",
    "#         mx = np.min([offset+halfwidth, xmax])\n",
    "#     else:\n",
    "#         mn = offset-halfwidth \n",
    "#         mx = offset+halfwidth\n",
    "#     x = np.arange(mn, mx)\n",
    "#     gx = np.exp(-(x-x0)**2/(2*sigma**2))\n",
    "#     gx /= sum(gx) # normalize\n",
    "#     return gx, mn, mx\n",
    "\n",
    "for i in range(iterations):\n",
    "    if i % 10 == 0:\n",
    "        print(i)\n",
    "    for j in range(N):\n",
    "        pt = all_pos[j, :, i]*res\n",
    "        ptx = pt[0]\n",
    "        pty = pt[1]\n",
    "        this_v = all_v[j, :, i]\n",
    "        local_dens = rho[int(ptx), int(pty), i]\n",
    "        sigma = sigma0*res\n",
    "        #sigma = np.min([L/3, 2*sigma0*(local_dens/rhom)**-0.5])*res\n",
    "        gx, mnx, mxx = gauss1d(ptx, sigma)\n",
    "        gy, mny, mxy = gauss1d(pty, sigma)\n",
    "        g = res**2*np.outer(gx, gy)\n",
    "        xrng = np.array(range(mnx, mxx)) % width\n",
    "        yrng = np.array(range(mny, mxy)) % width\n",
    "        rho_tuned[xrng[:, np.newaxis], yrng, i] += g\n",
    "        rv_tuned[xrng[:, np.newaxis], yrng, i, :] += g[:, :, np.newaxis]*this_v\n",
    "        \n",
    "nzind = rho_tuned[:]>0\n",
    "zind = rho_tuned[:]==0\n",
    "v_tuned[nzind, :] = rv_tuned[nzind, :]/rho_tuned[nzind, np.newaxis]\n",
    "v_tuned[zind, :] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(v[:, :, 5, 1], interpolation=\"nearest\", origin=\"lower\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(v_tuned[:, :, 5, 1], interpolation=\"nearest\", origin=\"lower\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save('arrays_bu.npy', rho_tuned, v_tuned, res, deltat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(rho), np.mean(rho_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(gx)/np.max(gx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
