### Code generated by NotebookLM!

import gurobipy as gp
import numpy as np
from typing import Tuple, List

def get_eigenvector_for_cut(X_solution: np.ndarray) -> np.ndarray:
    """
    Identifies if the given matrix X_solution violates the Positive Semidefinite (PSD)
    property and, if so, returns an eigenvector to construct a cutting plane.
    This simulates the 'separation oracle' [8, 14-17].

    Args:
        X_solution (np.ndarray): The current solution matrix X from the Gurobi model.

    Returns:
        np.ndarray or None: The eigenvector corresponding to the most negative eigenvalue
                            if a violation is found, otherwise None.
    """
    eigenvalues, eigenvectors = np.linalg.eigh(X_solution)
    min_eig = eigenvalues # Eigenvalues are sorted in ascending order

    # Use a small tolerance for floating-point comparisons
    if min_eig < -1e-6:
        # Return the eigenvector corresponding to the most negative eigenvalue [14, 15, 17]
        return eigenvectors[:, 0]
    else:
        return None # Matrix is approximately PSD

def greedy_rounding(Sigma: np.ndarray, k: int, max_cuts: int = 5, cut_type: str = "trailing_eigenvalue") -> Tuple[np.ndarray, float]:
    """
    Implements the greedy rounding method, augmented with an iterative cutting-plane
    scheme to enforce Positive Semidefiniteness (PSD) more strictly.

    This function illustrates the outer-approximation strategy described in the sources [9, 11].
    The initial model is a Second-Order Cone Program (SOCP),
    which is then iteratively refined by adding linear cutting planes [10, 12].

    Args:
        Sigma (np.ndarray): The w x w positive semidefinite matrix (G.T @ G).
        k (int): The target sparsity level.
        max_cuts (int): Maximum number of cutting planes to add.
        cut_type (str): Type of cutting plane to generate ('trailing_eigenvalue' or 'nuclear_norm').

    Returns:
        Tuple[np.ndarray, float]: A tuple containing the identified sparse coefficient vector
                                  and its Frobenius relative residual.

    Raises:
        ValueError: If k is out of bounds or cut_type is unsupported.
        RuntimeError: If Gurobi optimization fails.
    """
    w = Sigma.shape

    if not (0 <= k <= w):
        raise ValueError(f"Sparsity k must be between 0 and w. Got k={k}, w={w}.")
    if w == 0 or k == 0:
        return np.zeros(w), 0.0

    model = gp.Model("SparsePCA_SOCP_With_Cuts")
    model.setParam("OutputFlag", 0) # Suppress Gurobi console output

    # --- Phase 1: Initial SOCP Model Setup (including existing constraints 1-8) ---
    # This part sets up the convex relaxation, which is the starting point for the cutting-plane method [7, 9, 11, 12].

    z_vars = model.addMVar(w, vtype=gp.GRB.CONTINUOUS, lb=0.0, ub=1.0, name="z")
    X_vars = model.addMVar((w, w), vtype=gp.GRB.CONTINUOUS, name="X")
    abs_X_vars = model.addMVar((w, w), vtype=gp.GRB.CONTINUOUS, lb=0.0, name="absX")

    model.setObjective(gp.quicksum(Sigma[i,j] * X_vars[i,j] for i in range(w) for j in range(w)), gp.GRB.MINIMIZE)

    # 1. Symmetry of X [2]
    for i in range(w):
        for j in range(i + 1, w):
            model.addConstr(X_vars[i,j] == X_vars[j,i], name=f"X_symmetry_{i}_{j}")
    # 2. Sparsity Constraint on z [20]
    model.addConstr(gp.quicksum(z_vars[i] for i in range(w)) <= k, name="sparsity_sum_z")
    # 3. Normalization of X [20]
    model.addConstr(gp.quicksum(X_vars[i,i] for i in range(w)) == 1.0, name="trace_X_eq_1")
    # 4. Absolute Value Linking [20]
    for i in range(w):
        for j in range(w):
            model.addGenConstrAbs(abs_X_vars[i,j], X_vars[i,j], name=f"absX_link_{i}_{j}")
    # 5. Sparsity Bounds for X [20]
    M_matrix = np.ones((w, w)) * 0.5
    np.fill_diagonal(M_matrix, 1.0)
    for i in range(w):
        for j in range(w):
            model.addConstr(abs_X_vars[i,j] <= M_matrix[i,j] * z_vars[i], name=f"X_bound_z_{i}_{j}")
    # 6. Total Absolute Value Sum for X [20]
    model.addConstr(gp.quicksum(abs_X_vars[i,j] for i in range(w) for j in range(w)) <= k, name="total_abs_X_sum")

    # 7. Positive Semidefinite Relaxation (2x2 Principal Minors): X_ij^2 <= X_ii * X_jj [7].
    # Gurobi's quadratic constraint capabilities handle these, ensuring convexity.
    for i in range(w):
        model.addConstr(X_vars[i,i] >= 0, name=f"X_diag_nonneg_{i}") # Diagonal elements must be non-negative
        for j in range(i + 1, w): # Iterate only over upper triangle for unique pairs
            model.addQConstr(X_vars[i,j]*X_vars[i,j] <= X_vars[i,i]*X_vars[j,j], name=f"PSD_2x2_minor_{i}_{j}")

    # 8. Additional PSD-derived constraint for z_i: sum_{j=1}^{w} X_ij^2 <= z_i * X_ii [10].
    # This constraint further links X and z, critical for the relaxation.
    for i in range(w):
        model.addQConstr(gp.quicksum(X_vars[i,j]*X_vars[i,j] for j in range(w)) <= z_vars[i]*X_vars[i,i], name=f"X_sq_sum_bound_z_{i}")

    # --- Iterative Cutting Plane Addition ---
    # This loop dynamically adds linear cutting planes to the model [9, 11].
    # These cuts tighten the outer approximation of the PSD cone.

    for cut_iter in range(max_cuts):
        model.optimize()

        if model.status not in (gp.GRB.OPTIMAL, gp.GRB.SUBOPTIMAL):
            print(f"Gurobi failed to find optimal/suboptimal solution at iteration {cut_iter}. Status: {model.status}")
            break

        X_solution = X_vars.X.reshape((w, w)) # Retrieve the current X solution

        if cut_type == "trailing_eigenvalue":
            v_cut = get_eigenvector_for_cut(X_solution)
            if v_cut is None:
                print(f"X is approximately positive semidefinite after {cut_iter} cuts (tolerance). Stopping iterative cutting.")
                break # Solution satisfies PSD property within tolerance

            # Add a trailing eigenvalue cut: ⟨X, v v^T⟩ >= 0 [13-15, 17].
            # This is a linear constraint in terms of X_ij variables.
            vvT_matrix = np.outer(v_cut, v_cut)
            model.addConstr(gp.quicksum(X_vars[i,j] * vvT_matrix[i,j] for i in range(w) for j in range(w)) >= 0,
                            name=f"trailing_eig_cut_{cut_iter}")
            print(f"Added trailing eigenvalue cut {cut_iter+1}.")

        elif cut_type == "nuclear_norm":
            # For nuclear norm cuts, we check if ‖X‖∗ > tr(X) [19].
            # The nuclear norm (sum of singular values) of a symmetric matrix X [21].
            singular_values = np.linalg.svd(X_solution)[1] # U, s, Vt where s are singular values
            nuclear_norm_X = np.sum(singular_values) # ‖X‖∗ [19]
            trace_X = np.trace(X_solution) # tr(X) [19]

            if nuclear_norm_X > trace_X + 1e-6: # Check for violation with tolerance
                # Proposition 7 states that an optimal Y* for the cut is UU^T where X = UΛU^T [16].
                # For symmetric X, U from SVD will contain eigenvectors if singular values match eigenvalues.
                # If X has negative eigenvalues, we need the U from spectral decomposition.
                eigenvalues_X, eigenvectors_X = np.linalg.eigh(X_solution)
                # Y_cut for the nuclear norm cut is given by U U^T, where U contains the eigenvectors of X [16].
                Y_cut_matrix = eigenvectors_X @ eigenvectors_X.T # This is U U^T

                # Add the nuclear norm cut: ⟨X, Y_cut⟩ <= tr(X) [13, 19]
                model.addConstr(gp.quicksum(X_vars[i,j] * Y_cut_matrix[i,j] for i in range(w) for j in range(w)) <= gp.quicksum(X_vars[i,i] for i in range(w)),
                                name=f"nuclear_norm_cut_{cut_iter}")
                print(f"Added nuclear norm cut {cut_iter+1}.")
            else:
                print(f"Nuclear norm condition satisfied after {cut_iter} cuts (tolerance). Stopping iterative cutting.")
                break
        else:
            raise ValueError("Unsupported cut type. Choose 'trailing_eigenvalue' or 'nuclear_norm'.")

    # --- Phase 2: Greedy Rounding and Fixed-Support Eigenvector Problem ---
    # This phase uses the (potentially refined) continuous z_solution from Gurobi
    # to identify the 'k' most relevant terms and then solves a simpler, unconstrained
    # problem on this fixed support [22-24].

    z_solution = z_vars.X
    top_k_indices = np.argsort(z_solution)[-k:]
    top_k_indices = np.sort(top_k_indices) # Sort for consistent submatrix extraction

    c_full = np.zeros(w)
    if k > 0:
        # Extract the submatrix of Sigma corresponding to the selected support S [24, 25]
        Sigma_S = Sigma[np.ix_(top_k_indices, top_k_indices)]
        # Find the smallest eigenvector of Sigma_S [24-26]
        eigenvalues, eigenvectors = np.linalg.eigh(Sigma_S)
        smallest_eigenvalue_idx = 0
        c_S = eigenvectors[:, smallest_eigenvalue_idx]
        c_full[top_k_indices] = c_S
        norm_c_full = np.linalg.norm(c_full)
        c_final = c_full / norm_c_full if norm_c_full > 1e-10 else np.zeros(w)
    else:
        c_final = np.zeros(w)

    # Calculate the Frobenius relative residual [27-29]
    numerator_sq = c_final.T @ Sigma @ c_final
    numerator = np.sqrt(max(0, numerator_sq))
    denominator = np.sqrt(np.trace(Sigma))
    frobenius_residual = 0.0
    if denominator > 1e-10:
        frobenius_residual = numerator / denominator

    return c_final, frobenius_residual

# --- Example Usage ---
if __name__ == "__main__":
    w_demo = 50
    k_demo = 5
    np.random.seed(42)
    true_indices = np.random.choice(w_demo, k_demo, replace=False)
    true_c = np.zeros(w_demo)
    true_c[true_indices] = np.random.rand(k_demo) * 10
    true_c /= np.linalg.norm(true_c)

    Sigma_demo = np.identity(w_demo) * 100.0
    for i in true_indices:
        for j in true_indices:
            Sigma_demo[i, j] = np.random.rand() * 0.1
    Sigma_demo += np.random.rand(w_demo, w_demo) * 0.5
    Sigma_demo = (Sigma_demo + Sigma_demo.T) / 2
    min_eig = np.linalg.eigvalsh(Sigma_demo).min()
    if min_eig < 0:
        Sigma_demo += (abs(min_eig) + 1e-6) * np.identity(w_demo)

    print(f"Attempting greedy rounding regression for w={w_demo} terms and sparsity k={k_demo}...")
    try:
        # Example: Using trailing eigenvalue cuts (can also use cut_type="nuclear_norm")
        c_solution, residual = greedy_rounding(Sigma_demo, k_demo, max_cuts=3, cut_type="trailing_eigenvalue")

        print("\n--- Solution Summary ---")
        print(f"Requested sparsity (k): {k_demo}")
        print(f"Actual sparsity of identified solution: {np.sum(c_solution != 0)}")
        print(f"Frobenius relative residual: {residual:.6e}")

        identified_nonzero_indices = np.where(c_solution != 0) # Extract indices
        if len(identified_nonzero_indices) > 0:
            print("\nIdentified non-zero coefficients (index: value):")
            # Sort by absolute value descending for clarity
            sorted_by_abs_value_indices = identified_nonzero_indices[np.argsort(np.abs(c_solution[identified_nonzero_indices]))[::-1]]
            for idx in sorted_by_abs_value_indices[:10]: # Display up to top 10 for brevity
                print(f" Index {idx}: {c_solution[idx]:.6f}")
        else:
            print("\nNo non-zero coefficients identified.")

        print("\n--- Comparison to True (Synthetic) Support ---")
        print(f"True non-zero indices: {np.sort(true_indices)}")
        print(f"Identified non-zero indices: {np.sort(identified_nonzero_indices)}")

        intersection = np.intersect1d(true_indices, identified_nonzero_indices)
        precision = len(intersection) / len(identified_nonzero_indices) if len(identified_nonzero_indices) > 0 else 0
        recall = len(intersection) / len(true_indices) if len(true_indices) > 0 else 0
        f1_score = 0
        if (precision + recall) > 0:
            f1_score = 2 * (precision * recall) / (precision + recall)

        print(f"Precision (proportion of identified indices that are truly relevant): {precision:.2f}")
        print(f"Recall (proportion of truly relevant indices that were identified): {recall:.2f}")
        print(f"F1-score (harmonic mean of precision and recall): {f1_score:.2f}")

    except gp.GurobiError as e:
        print(f"Gurobi Error encountered: {e.message}")
    except RuntimeError as e:
        print(f"Runtime Error: {e}")
    except Exception as e:
        print(f"An unexpected error occurred: {e}")