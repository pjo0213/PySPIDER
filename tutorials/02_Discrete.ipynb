{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6b7f839-ef23-4e2e-8428-b043ef22341e",
   "metadata": {},
   "source": [
    "If you haven't already, please check out the [continuous tutorial](https://github.com/sibirica/PySPIDER/blob/main/tutorials/01_Continuous.ipynb) which goes over the simplest continuous case.\n",
    "\n",
    "### Imports\n",
    "\n",
    "You may need to run this cell (replacing the path with the location of the repository in your filesystem) in order to ensure that Python can find the imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4a7f719-d377-4a2e-9190-bb50f21c57f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# Suppress OpenMP deprecation warning from numba (using latest stable numba 0.61.2)\n",
    "# This is a known issue with OpenMP 5.0+ and is the recommended workaround\n",
    "os.environ['KMP_WARNINGS'] = '0'\n",
    "sys.path.insert(0, '../src')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b17770-81fa-4d74-8e58-23dc0d12b0b1",
   "metadata": {},
   "source": [
    "We will again use numpy to generate the dataset and matplotlib for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f372e707-2a68-45a5-a192-f970066adc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from matplotlib.animation import FuncAnimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046e6e08-5d51-4b07-8557-9d923de80438",
   "metadata": {},
   "source": [
    "We need essentially the same SPIDER imports as in the continuous case, except we now use the discrete version of SRDataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92ff7032-562d-4c37-a85b-3c94194cda34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PySPIDER.commons.library import Observable\n",
    "from PySPIDER.discrete.process_library_terms import SRDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6026cbfc-55ef-4b89-8172-ba17a24aa1d7",
   "metadata": {},
   "source": [
    "## Generating the dataset\n",
    "As a toy example, we generate 1600 particles on a square domain with periodic boundaries, which do not interact with each other and move at constant velocities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bf909eb-1e70-41be-a961-dda0bce98d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 80 # size of domain\n",
    "rho = 1 # density of particles\n",
    "N = int(rho*L**2) # number of particles\n",
    " \n",
    "deltat = 1.0 # time step\n",
    "vmax = 4/15 # max particle speed\n",
    "iterations = 250 # number of time steps\n",
    "\n",
    "# note that the array axes are (particle #, component of observable, t) - this is the correct input format for SPIDER\n",
    "positions = np.zeros(shape=(N,2,iterations))\n",
    "v = np.zeros(shape=(N,2,iterations))\n",
    "r = np.random.uniform(L/12, 11*L/12, size=(N,2))\n",
    "v0 = np.random.uniform(-vmax/np.sqrt(2), vmax/np.sqrt(2), size=(N,2))\n",
    "\n",
    "# evolve the particles forward with periodic boundaries\n",
    "for i in range(iterations):\n",
    "    r += deltat*v0\n",
    "    r[r>L] -= L\n",
    "    r[r<0] += L\n",
    "    \n",
    "    positions[:, :, i] = r\n",
    "    v[:, :, i] = v0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb038814-b909-46e2-a52f-73e02c044344",
   "metadata": {},
   "source": [
    "Pay careful attention to the format of the data: they are numpy arrays with axes (particle index, \\[optional components\\], t), For instance, the particle velocity $v$ corresponds to a 3D numpy array (#, 0=x or 1=y, t), whereas a scalar $s$ should be represented by a 2D array with axes (#, t). Currently, discrete SPIDER best supports datasets in two spatial dimensions, though it can run 3D with some modifications from this tutorial.\n",
    "\n",
    "If you want, you can generate a movie showing the particles and their velocities over time (requires an FFMpeg installation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58f528e9-57f0-4997-a7ec-e719ca6c9e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = False\n",
    "\n",
    "if plot:\n",
    "    fig, ax = plt.subplots(figsize=(6,6)) \n",
    "    qv = ax.quiver(r[:,0], r[:,1], v0[:,0], v0[:, 1], np.arctan2(v0[:,0], v0[:,1]), clim=[-np.pi, np.pi])\n",
    "    ax.axis([0, L, 0, L])\n",
    "    \n",
    "    def animate(i):\n",
    "        if i%10==0:\n",
    "            print(f\"t={i}\")\n",
    "        qv.set_offsets(positions[:, :, i])\n",
    "        return qv,\n",
    "\n",
    "    anim = FuncAnimation(fig, animate, np.arange(0, positions.shape[-1]), interval=1, blit=True)\n",
    "    plt.rcParams['animation.ffmpeg_path'] = '/Users/daniel/Documents/ffmpeg-7.1/ffmpeg' # replace this with your FFMPEG path\n",
    "    FFwriter = animation.FFMpegWriter(fps=24, codec=\"libx264\")\n",
    "    anim.save('burgers.mp4', writer=FFwriter, dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842729aa-1312-49aa-bc12-c1c17f14bfd1",
   "metadata": {},
   "source": [
    "### Defining and evaluating SPIDER objects\n",
    "\n",
    "Similarly to the continuous case, let's define an Observable object representing the particle velocity ${\\bf v}$ and create a mapping from the observable names to the numpy data arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed1bcb6b-ca5b-4902-b203-610ed244c23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_obs = Observable(string='v', rank=1)\n",
    "observables = [v_obs]\n",
    "data_dict = {}\n",
    "data_dict['v'] = v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85455ea6-f6be-4af6-af29-da2daa464175",
   "metadata": {},
   "source": [
    "Let's finish setting up the dataset. Unlike the continuous case, spatial measurements in discrete SPIDER use physical units, since there is no underlying grid. For the time axis, we still use grid points, with the conversion factor deltat.\n",
    "\n",
    "We also need to define two additional hyperparameters: the length scale of the coarse-graining kernel, kernel_sigma, and the number of grid points per physical unit, cg_res. Since the width of the domain is $L=80$ and the mean spacing between particles is 1, reasonable choice are 3 and 2 respectively (evaluating the coarse-grained quantities on a 240x240 grid and averaging over ~(2x2)^2=16 particles at each point). By default, a compactly-supported polynomial kernel is used, though Gaussian kernels are also implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0ad080e-21fa-4a71-93b5-175cbf3a965e",
   "metadata": {},
   "outputs": [],
   "source": [
    "world_size = np.array([L, L, iterations]) # dimensions of the dataset in physical units\n",
    "np.random.seed(1) # set the random seed so the random sample of integration domains is fixed\n",
    "\n",
    "# initial setup of the dataset object\n",
    "kernel_sigma = 3\n",
    "cg_res = 2\n",
    "# note the additional parameters particle_pos, kernel_sigma, cg_res, and deltat \n",
    "# which are not used in the continuous case\n",
    "srd = SRDataset(world_size=world_size, data_dict=data_dict, particle_pos=positions, observables=observables,\n",
    "                irreps=SRDataset.all_rank2_irreps(), kernel_sigma=kernel_sigma, cg_res=cg_res, deltat=deltat)\n",
    "# another useful parameter is rho_scale, which sets the scaling factor for the \n",
    "# coarse-grained density - e.g., rho_scale=100 divides rho by 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4413cde8-d660-4a28-b6eb-0b515ab63481",
   "metadata": {},
   "source": [
    "With the caveat of using physical units for the width of the integration domain, the rest of the setup works the same way as in the continuous case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9618170-0c9f-4fbf-91aa-ef3b297f6571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Rank 0 library has 42 terms:\n",
      "[ρ, ρ · ρ, ρ · ∂α² ρ, ρ · ∂t ρ, ρ · ∂t ∂α² ρ, ρ · ∂t² ρ, ρ · ∂t³ ρ, ρ · ∂α ρ[v_α], ρ · ∂t ∂α ρ[v_α], ρ · ρ[v_α · v_α], ρ · ∂t ρ[v_α · v_α], ∂α ρ · ∂α ρ, ∂α ρ · ∂t ∂α ρ, ∂α ρ · ρ[v_α], ∂α ρ · ∂t ρ[v_α], ∂α² ρ, ∂α² ρ · ∂t ρ, ∂α² ∂β² ρ, ∂t ρ, ∂t ρ · ∂t ρ, ∂t ρ · ∂t² ρ, ∂t ρ · ∂α ρ[v_α], ∂t ρ · ρ[v_α · v_α], ∂t ∂α ρ · ρ[v_α], ∂t ∂α² ρ, ∂t² ρ, ∂t² ∂α² ρ, ∂t³ ρ, ∂t⁴ ρ, ρ[v_α] · ρ[v_α], ρ[v_α] · ∂t ρ[v_α], ∂α ρ[v_α], ∂α² ∂β ρ[v_β], ∂t ∂α ρ[v_α], ∂t² ∂α ρ[v_α], ρ[v_α · v_α], ∂α ∂β ρ[v_α · v_β], ∂α² ρ[v_β · v_β], ∂t ρ[v_α · v_α], ∂t² ρ[v_α · v_α], ∂α ρ[v_α · v_β · v_β], ρ[v_α · v_α · v_β · v_β]]\n",
      "\n",
      "The Rank 1 library has 50 terms:\n",
      "[ρ · ∂α ρ, ρ · ∂α ∂β² ρ, ρ · ∂t ∂α ρ, ρ · ∂t² ∂α ρ, ρ · ρ[v_α], ρ · ∂β² ρ[v_α], ρ · ∂α ∂β ρ[v_β], ρ · ∂t ρ[v_α], ρ · ∂t² ρ[v_α], ρ · ∂β ρ[v_α · v_β], ρ · ∂α ρ[v_β · v_β], ρ · ρ[v_α · v_β · v_β], ∂α ρ, ∂α ρ · ∂β² ρ, ∂β ρ · ∂α ∂β ρ, ∂α ρ · ∂t ρ, ∂α ρ · ∂t² ρ, ∂α ρ · ∂β ρ[v_β], ∂β ρ · ∂α ρ[v_β], ∂β ρ · ∂β ρ[v_α], ∂α ρ · ρ[v_β · v_β], ∂β ρ · ρ[v_α · v_β], ∂α ∂β ρ · ρ[v_β], ∂β² ρ · ρ[v_α], ∂α ∂β² ρ, ∂t ρ · ∂t ∂α ρ, ∂t ρ · ρ[v_α], ∂t ρ · ∂t ρ[v_α], ∂t ∂α ρ, ∂t ∂α ∂β² ρ, ∂t² ρ · ρ[v_α], ∂t² ∂α ρ, ∂t³ ∂α ρ, ρ[v_α], ρ[v_α] · ∂β ρ[v_β], ρ[v_β] · ∂α ρ[v_β], ρ[v_α] · ρ[v_β · v_β], ∂β² ρ[v_α], ∂α ∂β ρ[v_β], ∂t ρ[v_α], ∂t ∂β² ρ[v_α], ∂t ∂α ∂β ρ[v_β], ∂t² ρ[v_α], ∂t³ ρ[v_α], ∂α ρ[v_β · v_β], ∂β ρ[v_α · v_β], ∂t ∂β ρ[v_α · v_β], ∂t ∂α ρ[v_β · v_β], ρ[v_α · v_β · v_β], ∂t ρ[v_α · v_β · v_β]]\n",
      "\n",
      "The Antisymmetric rank 2 library has 14 terms:\n",
      "[ρ · ∂α ρ[v_β], ρ · ∂t ∂α ρ[v_β], ∂α ρ · ∂t ∂β ρ, ∂α ρ · ρ[v_β], ∂α ρ · ∂t ρ[v_β], ∂t ρ · ∂α ρ[v_β], ∂t ∂α ρ · ρ[v_β], ρ[v_α] · ∂t ρ[v_β], ∂α ρ[v_β], ∂α ∂γ² ρ[v_β], ∂t ∂α ρ[v_β], ∂t² ∂α ρ[v_β], ∂α ∂γ ρ[v_β · v_γ], ∂α ρ[v_β · v_γ · v_γ]]\n",
      "\n",
      "The Symmetric trace-free rank 2 library has 34 terms:\n",
      "[ρ · ∂α ∂β ρ, ρ · ∂t ∂α ∂β ρ, ρ · ∂α ρ[v_β], ρ · ∂t ∂α ρ[v_β], ρ · ρ[v_α · v_β], ρ · ∂t ρ[v_α · v_β], ∂α ρ · ∂β ρ, ∂α ρ · ∂t ∂β ρ, ∂α ρ · ρ[v_β], ∂α ρ · ∂t ρ[v_β], ∂α ∂β ρ, ∂α ∂β ρ · ∂t ρ, ∂α ∂β ∂γ² ρ, ∂t ρ · ∂α ρ[v_β], ∂t ρ · ρ[v_α · v_β], ∂t ∂α ρ · ρ[v_β], ∂t ∂α ∂β ρ, ∂t² ∂α ∂β ρ, ρ[v_α] · ρ[v_β], ρ[v_α] · ∂t ρ[v_β], ∂α ρ[v_β], ∂α ∂β ∂γ ρ[v_γ], ∂α ∂γ² ρ[v_β], ∂t ∂α ρ[v_β], ∂t² ∂α ρ[v_β], ρ[v_α · v_β], ∂γ² ρ[v_α · v_β], ∂α ∂γ ρ[v_β · v_γ], ∂α ∂β ρ[v_γ · v_γ], ∂t ρ[v_α · v_β], ∂t² ρ[v_α · v_β], ∂γ ρ[v_α · v_β · v_γ], ∂α ρ[v_β · v_γ · v_γ], ρ[v_α · v_β · v_γ · v_γ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "srd.make_libraries(max_complexity=5, max_rho=2) # include at most two primes in each term\n",
    "for irrep in srd.irreps:\n",
    "    print(f\"The {irrep} library has {len(srd.libs[irrep].terms)} terms:\")\n",
    "    print(srd.libs[irrep].terms)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99448d9-987e-4c6e-99f8-b656e85e7209",
   "metadata": {},
   "source": [
    "Tip: using multiple weight functions per domain allows us to spend less time on coarse-graining, which is computationally expensive.\n",
    "\n",
    "To ensure accuracy of the results, it is important to set a large enough 'pad' parameter so that the coarse-graining doesn't rely on unavailable data outside the domain. For the default coarse-graining function, 4 kernel_sigma is sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2211a78-80dd-4ce7-9878-fee863c90e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dom_width = 10\n",
    "dom_time = 30\n",
    "\n",
    "srd.make_domains(ndomains=20, domain_size=[dom_width, dom_width, dom_time], pad=kernel_sigma*4)\n",
    "srd.make_weights(m=8, qmax=1)\n",
    "srd.set_LT_scale(L=1, T=1) # note that this line must go before make_library_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe66b87c-c296-4865-9e21-6abba4a16bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "srd.make_library_matrices(debug=False, parallel=True) # this may take a few minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba62ecf5-d945-4e8a-803c-a9a67a84615f",
   "metadata": {},
   "source": [
    "### Regression\n",
    "\n",
    "Regression works exactly the same way as for the continuous version of the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcba43d-8bec-4713-9f8a-140a1a0027e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- WORKING ON LIBRARY WITH IRREP Rank 0 AT COMPLEXITY 1 ---\n",
      "--- WORKING ON LIBRARY WITH IRREP Rank 1 AT COMPLEXITY 1 ---\n",
      "--- WORKING ON LIBRARY WITH IRREP Antisymmetric rank 2 AT COMPLEXITY 1 ---\n",
      "--- WORKING ON LIBRARY WITH IRREP Symmetric trace-free rank 2 AT COMPLEXITY 1 ---\n",
      "--- WORKING ON LIBRARY WITH IRREP Rank 0 AT COMPLEXITY 2 ---\n",
      "--- WORKING ON LIBRARY WITH IRREP Rank 1 AT COMPLEXITY 2 ---\n",
      "--- WORKING ON LIBRARY WITH IRREP Antisymmetric rank 2 AT COMPLEXITY 2 ---\n",
      "--- WORKING ON LIBRARY WITH IRREP Symmetric trace-free rank 2 AT COMPLEXITY 2 ---\n",
      "--- WORKING ON LIBRARY WITH IRREP Rank 0 AT COMPLEXITY 3 ---\n",
      "[0.01 s]\n",
      "Identified model: 1 · ∂t ρ + ∂α ρ[v_α] = 0 (order 3, residual 5.35e-07)\n",
      "(r_h = 8.38e-07)\n",
      "--- WORKING ON LIBRARY WITH IRREP Rank 1 AT COMPLEXITY 3 ---\n",
      "--- WORKING ON LIBRARY WITH IRREP Antisymmetric rank 2 AT COMPLEXITY 3 ---\n",
      "--- WORKING ON LIBRARY WITH IRREP Symmetric trace-free rank 2 AT COMPLEXITY 3 ---\n",
      "--- WORKING ON LIBRARY WITH IRREP Rank 0 AT COMPLEXITY 4 ---\n",
      "--- WORKING ON LIBRARY WITH IRREP Rank 1 AT COMPLEXITY 4 ---\n",
      "[0.01 s]\n",
      "Identified model: ∂t ρ[v_α] + 1 · ∂β ρ[v_α · v_β] = 0 (order 4, residual 7.44e-07)\n",
      "(r_h = 1.54e-06)\n",
      "--- WORKING ON LIBRARY WITH IRREP Antisymmetric rank 2 AT COMPLEXITY 4 ---\n",
      "--- WORKING ON LIBRARY WITH IRREP Symmetric trace-free rank 2 AT COMPLEXITY 4 ---\n",
      "--- WORKING ON LIBRARY WITH IRREP Rank 0 AT COMPLEXITY 5 ---\n",
      "[0.02 s]\n",
      "Identified model: 1 · ∂t ρ[v_α · v_α] + ∂α ρ[v_α · v_β · v_β] = 0 (order 5, residual 4.29e-07)\n",
      "(r_h = 6.62e-07)\n",
      "--- WORKING ON LIBRARY WITH IRREP Rank 1 AT COMPLEXITY 5 ---\n",
      "--- WORKING ON LIBRARY WITH IRREP Antisymmetric rank 2 AT COMPLEXITY 5 ---\n",
      "--- WORKING ON LIBRARY WITH IRREP Symmetric trace-free rank 2 AT COMPLEXITY 5 ---\n",
      "[0.02 s]\n",
      "Identified model: ∂t ρ[v_α · v_β] + 1 · ∂γ ρ[v_α · v_β · v_γ] = 0 (order 5, residual 2.84e-07)\n",
      "(r_h = 6.31e-07)\n"
     ]
    }
   ],
   "source": [
    "from PySPIDER.commons.identify_models import interleave_identify\n",
    "from PySPIDER.commons.sparse_reg_bf import Scaler, Initializer, ModelIterator, Residual, Threshold\n",
    "\n",
    "reg_opts_list = []\n",
    "for irrep in srd.irreps:\n",
    "    # for regression we need to construct Scaler, Initializer, ModelIterator, and Threshold objects\n",
    "    scaler = Scaler(sub_inds=None, char_sizes=srd.libs[irrep].col_weights, row_norms=None, unit_rows=True, train_fraction=1)\n",
    "\n",
    "    # compute initial k=10 guess via truncated inverse iteration\n",
    "    init = Initializer(method='power', start_k=10) \n",
    "    # complete up to 3 backward-forward passes over 1<=k<=10\n",
    "    iterator = ModelIterator(max_k=10, backward_forward=True, max_passes=3) \n",
    "    res = Residual(residual_type='matrix_relative') # Frobenius residual\n",
    "\n",
    "    # jump criterion: gamma=1.5, and continue to remove terms until r>delta\n",
    "    thres = Threshold(threshold_type='jump', gamma=1.5, delta=1e-8)\n",
    "    \n",
    "    # put everything together into an options dictionary\n",
    "    opts = {'scaler': scaler, 'initializer': init, 'residual': res,\n",
    "            'model_iterator': iterator, 'threshold': thres}\n",
    "    opts['verbose'] = False # setting to True outputs all of the debug info\n",
    "    reg_opts_list.append(opts)\n",
    "\n",
    "# now we can run the regression\n",
    "eqs, lambdas, reg_results, derived_eqs, excluded_terms = interleave_identify([srd.libs[i] for i in srd.irreps], \n",
    "reg_opts_list, threshold=1e-6, report_accuracy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c58a363-3afe-4cf6-81d0-01f827da00b3",
   "metadata": {},
   "source": [
    "The toy example of non-interacting particles is very nice, since all of moments of the density ${\\bf m}$ simply advect:\n",
    "$$D{\\bf m}=\\partial_t {\\bf m} + ({\\bf v} \\cdot \\nabla){\\bf m} = 0$$ This matches the results found by SPIDER, which include mass conservation $$\\partial_t \\rho + \\partial_\\alpha \\rho[v_\\alpha] = 0$$ and the multidimensional inviscid Burgers' equation $$\\partial_t \\rho[v_\\alpha] + \\partial_\\beta \\rho[v_\\alpha v_\\beta] = 0.$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
