{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "711aab73-b816-4191-9534-a5819c579808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case there are any problems with importing because path is wrong\n",
    "import sys\n",
    "sys.path.append('/Users/daniel/Princeton Dropbox/Daniel Gurevich/Research/discrete_sr/code/SPIDER_discrete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9866012",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from commons.weight import *\n",
    "from commons.utils import save, load\n",
    "from library import *\n",
    "from process_library_terms import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd7a7305-e5fb-4cd2-9998-521079f5ee63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 2, 512) (10000, 2, 512) 0.00125 [  1 512]\n",
      "[  1   1 512]\n"
     ]
    }
   ],
   "source": [
    "#positions, vs, deltat, dims = load('Matt/sim_n64_v03.npy', 4)\n",
    "#positions, vs, deltat, dims = load('Matt/sim_n1024.npy', 4)\n",
    "#positions, vs, deltat, dims = load('Matt/sim_n1024_default_v2.npy', 4)\n",
    "positions, vs, deltat, dims = load('Matt/sim_n10000.npy', 4)\n",
    "\n",
    "#Lsf = 100 # length scaling factor - to nondimensionalize rho\n",
    "#Tsf = 0.01 # time scaling factor - to keep v~O(1)\n",
    "#positions *= Lsf\n",
    "#vs *= (Lsf*Tsf)\n",
    "#deltat /= Tsf\n",
    "#dims[:-1] *= Lsf\n",
    "\n",
    "print(positions.shape, vs.shape, deltat, dims)\n",
    "\n",
    "Np, nt = positions.shape[0], positions.shape[2]\n",
    "world_size = np.array([dims[0], dims[0], dims[1]])\n",
    "print(world_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26b1dabd-8230-41c5-96a5-dfa86fcb3207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib import animation\n",
    "# from matplotlib.animation import FuncAnimation\n",
    "# from IPython.display import HTML\n",
    "# plt.rcParams['animation.ffmpeg_path'] = '/Users/daniel/Documents/ffmpeg-7.1/ffmpeg'\n",
    "\n",
    "# vid_file = 'Matt/sim_n10000.mp4'\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(6, 6))\n",
    "# qv = ax.quiver(positions[:, 0, -1], positions[:, 1, -1], 1, 0, clim=[-np.pi, np.pi])\n",
    "\n",
    "# def animate(i):\n",
    "#     if i % 10 == 0:\n",
    "#         print(i)\n",
    "#     qv.set_offsets(positions[:, :, i])\n",
    "#     norms = np.sqrt(vs[:, 0, i] ** 2 + vs[:, 1, i] ** 2)\n",
    "#     qv.set_UVC(vs[:, 0, i] / norms, vs[:, 1, i] / norms, np.angle(vs[:, 0, i] + 1.0j * vs[:, 1, i]))\n",
    "#     return qv,\n",
    "\n",
    "# anim = FuncAnimation(fig, animate, np.arange(0, positions.shape[-1]), interval=1, blit=True)\n",
    "# FFwriter = animation.FFMpegWriter(fps=24, codec=\"libx264\")\n",
    "# anim.save(vid_file, writer=FFwriter, dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f02fabd-7a50-418b-ad5a-61a2a61f4a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8486350690926066\n"
     ]
    }
   ],
   "source": [
    "%%prun # profiling\n",
    "\n",
    "data_dict = {}\n",
    "data_dict['v'] = vs\n",
    "v_obs = Observable(string='v', rank=1)\n",
    "observables = [v_obs]\n",
    "\n",
    "# fix random seed\n",
    "np.random.seed(1)\n",
    "\n",
    "# initial setup of dataset\n",
    "corr_L = 0.02 #0.2\n",
    "#corr_T = 0.01 #0.1\n",
    "kernel_sigma = 0.02 # 0.05\n",
    "cg_res = 256\n",
    "srd = SRDataset(world_size=world_size, data_dict=data_dict, particle_pos=positions, observables=observables, rho_scale=Np,\n",
    "                irreps=SRDataset.all_rank2_irreps(), kernel_sigma=kernel_sigma, cg_res=cg_res, deltat=deltat, cutoff=6)\n",
    "v_est = np.mean(np.abs(vs))*2**0.5\n",
    "print(v_est)\n",
    "\n",
    "# initialize libraries, domains, and weights\n",
    "#srd.make_libraries(max_complexity=4, max_rho=2)\n",
    "#srd.make_libraries(max_complexity=5, max_rho=2)\n",
    "srd.make_libraries(max_complexity=6, max_rho=2)\n",
    "\n",
    "dom_width = 0.1 # 0.3\n",
    "dom_time = 40\n",
    "#srd.make_domains(ndomains=10, domain_size=[dom_width, dom_width, dom_time], pad=kernel_sigma*4) #*8\n",
    "srd.make_domains(ndomains=30, domain_size=[dom_width, dom_width, dom_time], pad=kernel_sigma*4) #*8\n",
    "srd.make_weights(m=8, qmax=1)\n",
    "srd.set_LT_scale(L=corr_L, T=corr_L/v_est) # note that this line must go before make_library_matrices\n",
    "#srd.set_LT_scale(L=corr_L, T=corr_T) # note that this line must go before make_library_matrices\n",
    "srd.make_library_matrices(debug=False)\n",
    "\n",
    "save('Q_gauss1024.npy', srd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ce83dd-ff43-458a-a595-1526b457c978",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats._stats import gaussian_kernel_estimate\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from IPython.display import HTML\n",
    "\n",
    "def coarse_grain_slice(t, sigma, field='rho', component=None):\n",
    "    pt_pos = positions[:, :, t]\n",
    "    weights = np.ones(pt_pos.shape[0], dtype=np.float64)\n",
    "    if field == 'v':\n",
    "        weights *= vs[:, component, t]\n",
    "    xx, yy = np.meshgrid(np.linspace(0, 1, cg_res), np.linspace(0, 1, cg_res))\n",
    "    xi = np.vstack([xx.ravel(), yy.ravel()]).T\n",
    "\n",
    "    sigma_sq = sigma ** 2\n",
    "    # Check scipy version. If it's lower than 1.10, use inverse_covariance, otherwise use Cholesky\n",
    "    if int(scipy.__version__.split(\".\")[0]) <= 1 and int(scipy.__version__.split(\".\")[1]) < 10:\n",
    "        inv_cov = np.eye(2) / sigma_sq\n",
    "    else:\n",
    "        inv_cov = np.eye(2) * sigma_sq\n",
    "        inv_cov = np.linalg.cholesky(inv_cov[::-1, ::-1]).T[::-1, ::-1]\n",
    "    density = gaussian_kernel_estimate['double'](pt_pos, weights[:, None], xi, inv_cov,\n",
    "                                                 np.float64)\n",
    "    output = np.reshape(density[:, 0], xx.shape) / 1e4\n",
    "    return output\n",
    "\n",
    "t = 100\n",
    "sigma = 0.02\n",
    "rho_cg = coarse_grain_slice(t, sigma, field='rho')\n",
    "vx_cg = coarse_grain_slice(t, sigma, field='v', component=0)\n",
    "vy_cg = coarse_grain_slice(t, sigma, field='v', component=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad57c12-784c-40de-a1f3-c22b4318549e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1) = plt.subplots(1, 1, figsize=(12, 12))\n",
    "im1 = ax1.imshow(rho_cg)\n",
    "\n",
    "frame = plt.gca()\n",
    "frame.axes.get_xaxis().set_visible(False)\n",
    "frame.axes.get_yaxis().set_visible(False)\n",
    "#colorbar\n",
    "divider = make_axes_locatable(ax1)\n",
    "cax1 = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "cb1 = plt.colorbar(im1, cax=cax1)\n",
    "cb1.ax.tick_params(labelsize=24) \n",
    "\n",
    "name = f'cg_rho_{sigma}.png'\n",
    "plt.savefig(name, dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ae134d-9af1-4628-8dd0-7af09a392cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1) = plt.subplots(1, 1, figsize=(12, 12))\n",
    "im1 = ax1.imshow(vx_cg)\n",
    "\n",
    "frame = plt.gca()\n",
    "frame.axes.get_xaxis().set_visible(False)\n",
    "frame.axes.get_yaxis().set_visible(False)\n",
    "#colorbar\n",
    "divider = make_axes_locatable(ax1)\n",
    "cax1 = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "cb1 = plt.colorbar(im1, cax=cax1)\n",
    "cb1.ax.tick_params(labelsize=24) \n",
    "\n",
    "name = f'cg_vx_{sigma}.png'\n",
    "plt.savefig(name, dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121b875b-54a5-4a23-865c-cce55abb6545",
   "metadata": {},
   "outputs": [],
   "source": [
    "from commons.identify_models import *\n",
    "import copy\n",
    "\n",
    "#srd = load('Q_gauss1024.npy', 1)\n",
    "libs = srd.libs\n",
    "\n",
    "reg_opts_list = []\n",
    "for irrep in srd.irreps:\n",
    "    #print(np.linalg.norm(libs[irrep].Q, axis=0))\n",
    "    # for regression we now need to construct a Scaler, Initializer, ModelIterator, and Threshold\n",
    "    scaler = Scaler(sub_inds=None, char_sizes=libs[irrep].col_weights, row_norms=None, unit_rows=True, train_fraction=1)\n",
    "    #init = Initializer(method='combinatorial', start_k=3)\n",
    "    init = Initializer(method='combinatorial', start_k=9999)\n",
    "    #init = Initializer(method='power', start_k=10)\n",
    "    #res = Residual(residual_type='fixed_column', anchor_col=0)\n",
    "    #res = Residual(residual_type='dominant_balance')\n",
    "    res = Residual(residual_type='matrix_relative')\n",
    "    #res = Residual(residual_type='accuracy')\n",
    "    \n",
    "    #iterator = ModelIterator(max_k=10, backward_forward=True, max_passes=1)\n",
    "    iterator = ModelIterator(max_k=len(libs[irrep].terms), backward_forward=False, max_passes=1)\n",
    "    thres = Threshold(threshold_type='jump', gamma=1.5, delta=1e-8, n_terms=None)\n",
    "    #thres = Threshold(threshold_type='information', ic=AIC)\n",
    "    \n",
    "    opts = {'scaler': scaler, 'initializer': init, 'residual': res,\n",
    "            'model_iterator': iterator, 'threshold': thres}\n",
    "    opts['verbose'] = False\n",
    "    opts['inhomog'] = False\n",
    "    opts['inhomog_col'] = None\n",
    "    reg_opts_list.append(opts)\n",
    "\n",
    "\n",
    "eqs, lambdas, reg_results, derived_eqs, excluded_terms = interleave_identify([libs[i] for i in srd.irreps], \n",
    "    reg_opts_list, threshold=2e-3, experimental=True, report_accuracy=True,\n",
    "    #reg_opts_list, threshold=4e-2, experimental=True)\n",
    "    #print_opts={'num_format': '{0:.3g}', 'latex_output': True}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65d503b-eee9-4517-8183-7589679d2173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "for i, res in enumerate(reg_results):\n",
    "    if len(eqs[i].terms)>1:\n",
    "        all_lambdas = res.all_lambdas\n",
    "        print(all_lambdas)\n",
    "        all_xis = res.all_xis\n",
    "        xi_values = res.xi\n",
    "        sublibrary_terms = res.sublibrary\n",
    "        equations = []\n",
    "        print(eqs[i].coeffs)\n",
    "        #equation_terms = [f\"{xi:.1e} {term}\" for xi, term in zip(xi_values, sublibrary_terms) if abs(xi) > 1e-15]\n",
    "        #equation_string = \" + \".join(equation_terms)\n",
    "        equation_string = str(eqs[i].pstr(**{'num_format': '{0:.3g}', 'latex_output': False}))\n",
    "        print(equation_string)\n",
    "    \n",
    "        \n",
    "        plt.figure(figsize=(8, 5))\n",
    "        #plt.scatter(range(2, len(all_lambdas) + 1), all_lambdas[1:], color='k')#, label=\"Lambda values\") # range(1, \n",
    "        max_terms = min(10, len(all_lambdas))\n",
    "        plt.scatter(range(1, max_terms+1), all_lambdas[:10], color='k')#, label=\"Lambda values\")\n",
    "\n",
    "        \n",
    "        # Set log scale for y-axis\n",
    "        plt.yscale(\"log\")\n",
    "\n",
    "        fs = 18\n",
    "        fs2 = 14\n",
    "        plt.xlabel(\"k\", fontsize=fs)\n",
    "        plt.ylabel(\"r\", fontsize=fs)\n",
    "        #plt.title(f\"Equation: {equation_string}\")  # Use the computed equation as the title\n",
    "        #plt.xticks(range(2, len(all_lambdas) + 1), fontsize=fs2)  # Ensure x-axis ticks match the number of equations\n",
    "        plt.xticks(range(1, max_terms+1), fontsize=fs2)  # Ensure x-axis ticks match the number of equations\n",
    "\n",
    "        plt.yticks(fontsize=fs2)\n",
    "        plt.legend()\n",
    "        plt.grid(True, linestyle=\"--\", linewidth=0.5) # which=\"both\"\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c94b5f-821f-4970-b570-21006b49a405",
   "metadata": {},
   "outputs": [],
   "source": [
    "1-0.99999995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba64560a-bc92-4b94-a2f7-9842f1a87d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in excluded_terms.items():\n",
    "    print(len(v), v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4989e647-edb8-403e-9cfc-45caf91df611",
   "metadata": {},
   "outputs": [],
   "source": [
    "from commons.identify_models import *\n",
    "import copy\n",
    "\n",
    "#srd = load('Q_gauss1024.npy', 1)\n",
    "libs = srd.libs\n",
    "\n",
    "reg_opts_list = []\n",
    "for irrep in srd.irreps:\n",
    "    #print(np.linalg.norm(libs[irrep].Q, axis=0))\n",
    "    # for regression we now need to construct a Scaler, Initializer, ModelIterator, and Threshold\n",
    "    scaler = Scaler(sub_inds=None, char_sizes=libs[irrep].col_weights, row_norms=None, unit_rows=True, train_fraction=1)\n",
    "    #init = Initializer(method='combinatorial', start_k=3)\n",
    "    #init = Initializer(method='combinatorial', start_k=9999)\n",
    "    init = Initializer(method='power', start_k=10)\n",
    "    #res = Residual(residual_type='fixed_column', anchor_col=0)\n",
    "    #res = Residual(residual_type='dominant_balance')\n",
    "    res = Residual(residual_type='accuracy')\n",
    "    \n",
    "    iterator = ModelIterator(max_k=10, backward_forward=True, max_passes=10)\n",
    "    #iterator = ModelIterator(max_k=len(libs[irrep].terms), backward_forward=False, max_passes=1)\n",
    "    thres = Threshold(threshold_type='jump', gamma=1.5, delta=1e-8, n_terms=None)\n",
    "    #thres = Threshold(threshold_type='information', ic=AIC)\n",
    "    \n",
    "    opts = {'scaler': scaler, 'initializer': init, 'residual': res,\n",
    "            'model_iterator': iterator, 'threshold': thres}\n",
    "    opts['verbose'] = False\n",
    "    opts['inhomog'] = False\n",
    "    opts['inhomog_col'] = None\n",
    "    reg_opts_list.append(opts)\n",
    "\n",
    "eqs, lambdas, reg_results, derived_eqs, excluded_terms = interleave_identify([libs[i] for i in srd.irreps], \n",
    "#reg_opts_list, threshold=2e-2, experimental=True)\n",
    "reg_opts_list, threshold=4e-2, experimental=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b90cd6-bbfb-43ab-a81b-742b14e81fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(srd.scale_dict)\n",
    "for irrep in srd.irreps:\n",
    "    # don't forget preprocessing\n",
    "    Q = srd.libs[irrep].Q/srd.libs[irrep].col_weights # reweight columns\n",
    "    for i in range(Q.shape[0]): # normalize rows\n",
    "        Q[i, :] /= np.linalg.norm(Q[i, :])\n",
    "    [U, S, V] = np.linalg.svd(Q)\n",
    "    print(np.linalg.norm(Q)/max(S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab71bb5a-197b-4bf7-8dc5-4e5b56feb091",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib1 = libs[srd.irreps[1]]\n",
    "for i, term, size in zip(list(range(len(lib1.terms))), lib1.terms, lib1.col_weights):\n",
    "    print(i, term, size, term.complexity)\n",
    "print(next(regex_find(lib1.terms, r'∂t ρ\\[v_α\\]')))\n",
    "print(next(regex_find(lib1.terms, r'ρ · ∂t ρ\\[v_α\\]')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5a4d6e-8568-4f1a-855e-079886bfff24",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib0 = libs[srd.irreps[0]]\n",
    "for i, term, size in zip(list(range(len(lib0.terms))), lib0.terms, lib0.col_weights):\n",
    "    print(i, term, size, term.complexity)\n",
    "print(next(regex_find(lib0.terms, r'∂α² ρ')))\n",
    "print(next(regex_find(lib0.terms, r'∂t² ρ')))\n",
    "print(next(regex_find(lib0.terms, r'∂t ∂α ρ\\[v_α\\]')))\n",
    "print(next(regex_find(lib0.terms, r'ρ · ∂α² ρ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bb022b-5a1f-4e19-9b45-f629fbf0120f",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_norms = np.linalg.norm(lib0.Q/lib0.col_weights, axis=0)\n",
    "print(len(col_norms), lib0.Q.shape)\n",
    "for term, norm in zip(lib0.terms, col_norms/max(col_norms)):\n",
    "    print(term, norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea93b2dc-bf13-4ed5-bcbc-bc0f4c5d20c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib0 = libs[srd.irreps[0]]\n",
    "scaler = Scaler(sub_inds=None, char_sizes=lib0.col_weights, row_norms=None, train_fraction=1, unit_rows=True)\n",
    "init = Initializer(method='combinatorial', start_k=3)\n",
    "#init = Initializer(method='combinatorial', start_k=9999)\n",
    "#init = Initializer(method='power', start_k=15)\n",
    "#res = Residual(residual_type='fixed_column', anchor_col=0)\n",
    "#res = Residual(residual_type='dominant_balance')\n",
    "res = Residual(residual_type='matrix_relative')\n",
    "\n",
    "iterator = ModelIterator(max_k=15, backward_forward=True, max_passes=3)\n",
    "#iterator = ModelIterator(max_k=len(libs0.terms), backward_forward=True, max_passes=1)\n",
    "\n",
    "thres = Threshold(threshold_type='jump', gamma=1.5, delta=1e-8, n_terms=None)\n",
    "#thres = Threshold(threshold_type='information', ic=AIC)\n",
    "\n",
    "opts = {'scaler': scaler, 'initializer': init, 'residual': res,\n",
    "        'model_iterator': iterator, 'threshold': thres}\n",
    "\n",
    "opts['inhomog'] = True\n",
    "#opts['inhomog_col'] = 1 # ρ²\n",
    "opts['inhomog_col'] = 15 # ∂α² ρ\n",
    "#opts['inhomog_col'] = 25 # ∂t² ρ\n",
    "\n",
    "remove_terms = [34, 2] # ∂t ∂α ρ[v_α], ρ · ∂α² ρ\n",
    "for term in remove_terms:\n",
    "    if term in opts['scaler'].sub_inds:\n",
    "        opts['scaler'].sub_inds.remove(term) \n",
    "opts['scaler'].reset_inds(opts['scaler'].sub_inds)\n",
    "\n",
    "reg_result = sparse_reg_bf(lib0.Q, **opts)\n",
    "zipped = [(lib0.terms[i], c) for i, c in enumerate(reg_result.xi) if c != 0]\n",
    "eqn = Equation([e[0] for e in zipped], [e[1] for e in zipped])\n",
    "\n",
    "print(eqn, \"; residual:\", reg_result.lambd)\n",
    "accuracy = compute_accuracy(lib0.Q, reg_result.xi, opts['scaler'])\n",
    "print(f'(Accuracy = {accuracy:.2e})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc04ec26-0bcd-4d66-940f-5380bbc79d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib1 = libs[srd.irreps[1]]\n",
    "scaler = Scaler(sub_inds=None, char_sizes=lib1.col_weights, row_norms=None, train_fraction=1, unit_rows=True)\n",
    "init = Initializer(method='combinatorial', start_k=3)\n",
    "#init = Initializer(method='combinatorial', start_k=9999)\n",
    "#init = Initializer(method='power', start_k=10)\n",
    "#res = Residual(residual_type='fixed_column', anchor_col=0)\n",
    "#res = Residual(residual_type='dominant_balance')\n",
    "res = Residual(residual_type='matrix_relative')\n",
    "\n",
    "iterator = ModelIterator(max_k=10, backward_forward=True, max_passes=3)\n",
    "#iterator = ModelIterator(max_k=len(lib1.terms), backward_forward=True, max_passes=1)\n",
    "\n",
    "thres = Threshold(threshold_type='jump', gamma=1.5, delta=1e-8, n_terms=None)\n",
    "#thres = Threshold(threshold_type='information', ic=AIC)\n",
    "\n",
    "opts = {'scaler': scaler, 'initializer': init, 'residual': res,\n",
    "        'model_iterator': iterator, 'threshold': thres}\n",
    "\n",
    "opts['inhomog'] = True\n",
    "opts['inhomog_col'] = 39 # dt rho[v_i]\n",
    "opts['verbose'] = False\n",
    "\n",
    "remove_terms = [7] # rho * dt rho[v_i]\n",
    "for term in remove_terms:\n",
    "    if term in opts['scaler'].sub_inds:\n",
    "        opts['scaler'].sub_inds.remove(term) \n",
    "opts['scaler'].reset_inds(opts['scaler'].sub_inds)\n",
    "\n",
    "reg_result = sparse_reg_bf(lib1.Q, **opts)\n",
    "zipped = [(lib1.terms[i], c) for i, c in enumerate(reg_result.xi) if c != 0]\n",
    "eqn = Equation([e[0] for e in zipped], [e[1] for e in zipped])\n",
    "\n",
    "print(eqn, \"; residual:\", reg_result.lambd)\n",
    "accuracy = compute_accuracy(lib1.Q, reg_result.xi, opts['scaler'])\n",
    "print(f'(Accuracy = {accuracy:.2e})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1ae667-1ec0-4249-919f-7c505acd86aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
